---
title: "Orebro RNA-seq analysis"
author: "Rodrigo Arcoverde Cerveira"
date: '`r format(Sys.Date(), "%Y-%m-%d")`'
output: html_document
abstract: Ã–rebro study RNA-seq data analysis.
knit: (function(inputFile, encoding) {
          rmarkdown::render(inputFile,
                            encoding = encoding, 
                            output_file = paste0(
                              xfun::sans_ext(inputFile), '_', Sys.Date(), '.html'),
                                output_dir = "../results/lab_book/")})
editor_options: 
  chunk_output_type: console
---

```{r global.options, include=FALSE}
#setting up figures and chunks messages

knitr::opts_knit$set(echo = TRUE,
                     root.dir = getwd(),
                     fig.width = 6, fig.height = 5,
                     fig.align = "center",
                     out.width = 768,
                     fig.pos = "H",
                     warning = FALSE, 
                     message = FALSE)
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE,
                      fig.width = 6, fig.height = 5,
                     fig.align = "center",
                     out.width = 768,
                     fig.pos = "H")

result.dir <- paste0("results/",Sys.Date(),"/")
figures.dir <- paste0("results/",Sys.Date(),"/", "figures/")
## creates result.dir with date in if not existent
ifelse(isFALSE(dir.exists(paste0("../",result.dir))), dir.create(paste0("../",result.dir),recursive = TRUE),"Result directory for today exists already!")
ifelse(isFALSE(dir.exists(paste0("../",figures.dir))), dir.create(paste0("../",figures.dir),recursive = TRUE),"Result directory for today exists already!")

options(stringsAsFactors = FALSE) 
```

## Loading libraries

```{r}
#if you do not have libraries, they are located in either CRAN or Bioconductor
library(kableExtra)
library(forcats)
library(caret)
library(C50)
library(mgsub)
library(DESeq2) 
library(pheatmap) 
library(ggplot2) 
library(ggrepel) 
library(RColorBrewer) 
library(limma) 
library(edgeR) 
library(enrichR) 
library(gridExtra) 
library(stringr)
library(ggVennDiagram)
library(dplyr) 
library(ensembldb)
library(EnsDb.Hsapiens.v86)
library(factoextra)
library(rafalib)
library(plotly)
library(tibble)

```

## Download and load data


```{r}
#reading data
counts_raw <- data.table::fread("../data/proces-data_core-facility/subreadCounts_hg38ens_minus_frag.txt", header = TRUE, sep = "\t") %>%  as.data.frame()

sampleTable <- read.table("../data/proces-data_core-facility/sample_metadata.csv", sep = ",", header = TRUE) %>%
  mutate(dose = plyr::mapvalues(visit, from = c(1,2,4,5), to = c("0_dose1","24_dose1","0_dose2","24_dose2")))

## renaming genes based on emsembl annotation
edb <- EnsDb.Hsapiens.v86
edb_genes <- genes(edb) %>% as.data.frame()

counts_raw <- counts_raw %>%
  dplyr::select(-c(Chr, Start, End, Strand, Length)) %>%
  dplyr::mutate(Geneid = plyr::mapvalues(x = counts_raw$Geneid, from = edb_genes$gene_id, to = edb_genes$symbol, warn_missing = FALSE))

## aggregate and sum up genes with same gene symbol, which were basically non-coding RNAs
counts_raw <- aggregate(counts_raw[,-1], list(Geneid=counts_raw[,1]), FUN = sum)
rownames(counts_raw) <- counts_raw$Geneid
counts_raw <- dplyr::select(counts_raw, -c(Geneid))

```

## Inspect raw data

Matching metadata to countTable and plotting the raw counts histogram for first visual inspection.  

```{r}
#Synchonize count data with sample table
counts_raw <- counts_raw[, pmatch(sampleTable$sample_ID, colnames(counts_raw))]
colnames(counts_raw) <- sampleTable$sample_ID
all(rownames(sampleTable$sample_ID) == colnames(counts_raw))

#Visualize distribution of raw counts w/ boxplot and density plot
{
  pdf(paste0("../", figures.dir,"raw_counts_QC.pdf"), width = 10,  height = 8, compress = TRUE )
  rafalib::mypar(1,2,mar=c(10,3,3,2))
  boxplot(log2(as.matrix(counts_raw)+1),ylab=expression('Log'[2]~'Read counts'),las=2,main="Raw data")
  hist(log2(as.matrix(counts_raw)+1),ylab="",las=2,main="Raw data")
  par(mfrow=c(1,1))
  dev.off()
}
```

## Filter data

Removing reads with the log2 of the counts per million (cpm) lower than 1.

```{r}
#See if sample need to be discarded based on the number of genes detected -> no
{
  pdf(paste0("../", figures.dir,"number_detected_genes.pdf"), width = 10,  height = 8, compress = TRUE )
  par(mar=c(10,4,3,4))
  barplot(colSums(counts_raw>3),ylab="Number of detected genes",las=2)
  abline(h=median(colSums(counts_raw>3)))
  dev.off()
}
#Filter low counts
meanLog2CPM <- rowMeans(log2(cpm(counts_raw) + 1)) 
hist(meanLog2CPM)

counts_filtered <- counts_raw[meanLog2CPM > 1, ] 

#Plot distribution of the filtered counts
{
  pdf(paste0("../", figures.dir,"filtered_counts.pdf"), width = 10,  height = 8, compress = TRUE )
  rafalib::mypar(1,2,mar=c(10,3,3,2))
  boxplot(log2(as.matrix(counts_filtered)+1),ylab=expression('Log'[2]~'Read counts'),las=2,main="Filtered data")
  hist(log2(as.matrix(counts_filtered)+1),ylab="",las=2,main="Filtered data")
  par(mfrow=c(1,1))
  dev.off()
}
#Plot for detection rate across genes for raw and filtered counts
hist(rowSums(counts_raw>3))
hist(rowSums(counts_filtered>3))
```

## DESeq object creation and data QC

Generating the DESeq dataset.

```{r}
# create DESeq object
dds <- DESeqDataSetFromMatrix(counts_raw,
                              design = ~ dose + group,
                              colData = sampleTable)

#Normalize
normCounts <- vst(dds, blind = TRUE) 

#Distribution
hist(assay(normCounts))

#Sample heatmap
sampleDist <- cor(assay(dds), method = "spearman") 

Metadata <- data.frame(sampleTable$group, sampleTable$dose)
names(Metadata) <- c("Group","Dose")
rownames(Metadata) <- sampleTable$sample_ID

```

```{r}

colors<-colorRampPalette(rev(brewer.pal(n=7,name="RdBu")))(255)

{
  pheatmap(sampleDist, 
           color = colors,
           clustering_distance_rows = as.dist(1 - sampleDist),
           clustering_distance_cols = as.dist(1 - sampleDist), 
           show_rownames = F,
           show_colnames = F,
           clustering_method = "ward.D2",
           annotation_col = Metadata)
}


```


## Principal Component Analyais (PCA)

Dimensionality reduction for evaluating outliers and global sample clusters for both quality control but also for primary exploratory analysis.

```{r}

#Sample PCA
pcaRes <- prcomp(t(assay(normCounts)))
varExp <- round(summary(pcaRes)[[1]],digits = 2)

pcaDF <- data.frame(
  PC1 = pcaRes$x[, 1],
  PC2 = pcaRes$x[, 2],
  Group = sampleTable$group,
  Sample = sampleTable$sample_ID,
  Dose = sampleTable$dose)

pcaPlot <- ggplot( pcaDF, mapping = aes(x = PC1, y = PC2, color = Group, label = Sample)) + 
  geom_point(aes(shape = Dose), size = 3) +
  labs(x = paste0("PC1 (", varExp[1], " %)"), y = paste0("PC2 (", varExp[2], " %)")) + 
  theme(axis.text = element_text(size = 12), legend.text = element_text(size = 10)) +
  scale_color_manual(values = brewer.pal(3, "Accent")) +
  cowplot::theme_cowplot()

print(pcaPlot)

## exploring which variables contribue the most for each PC
var <- get_pca_var(pcaRes)
var$contrib %>%
  as.data.frame() %>%
  arrange(desc(Dim.1)) %>%
  head()
# many are related to sex, thus for the later analysis we should remove those and also normalize per sex the counts
  
```


## Statistical analysis and fitting a model

```{r}
#Step 1: Define design matrix
designMatrix <- model.matrix(~ 0 + dose, data = sampleTable) 
#designMatrix[1:5, 1:5]
designMatrix
#Step 2: Define contrast matrix
contrastMatrix <- makeContrasts(ICUstatICU - ICUstatNonICU , levels=make.names(colnames(designMatrix)))


#Step 3: Fit model
dge <- DGEList(countTable)
dge <- calcNormFactors(dge)
dge <- estimateDisp(dge, designMatrix, robust = TRUE) 
fit <- glmQLFit(dge, designMatrix, robust = TRUE)

#Step 4: Perform hypothesis testing
res <- glmQLFTest(fit, contrast = contrastMatrix)
res <- topTags(res, n = nrow(countTable))
sigRes <- subset(res$table, FDR < 0.05 & abs(logFC) > 1) 

kableExtra::kable(sigRes) %>%
  kableExtra::scroll_box(width = "100%", height = "100px")



```


## Visualization plot of DEG

Volcano plot for data exploranotory analysis, filtering for significant values with False Discovery Rate < 0.05 and log fold change greater than 1.

```{r}

#Visualize results
volcanoPlot <- ggplot(res$table, aes(x = logFC, y = -log10(FDR),
                                     color = ifelse(FDR < 0.05 & abs(logFC) > 1, "darkred", "grey"))) +
  geom_point() +
  xlab(expression("Fold Change (Log"[2]*")")) +
  ylab(expression("Adjusted P value (Log"[10]*")")) +
  geom_vline(xintercept = c(-1, 1), linetype = "dotted", size = 1) + 
  geom_hline(yintercept = -log10(0.05), linetype = "dotted", size = 1) + 
  theme_minimal() +
  theme(legend.position = "none") +
  scale_colour_manual(values = c("darkred", "grey", "steelblue")) + 
  geom_text_repel(aes(x = logFC, y = -log10(FDR), 
                      label = rownames(res$table)[1:10],
                      size = 2, color = "steelblue"),
                  data = res$table[1:10, ])
print(volcanoPlot)

```

## Enrichment analysis

Selecting two different databases for search for enrichment analysis. The databases selected were "GO_Biological_Process_2021" and "KEGG_2021_Human". Testing also the Blood Transcriptome modules presented in [Li et al. 2014](10.1038/ni.2789) using some GSEA package.

```{r}
#Enrichment analysis

enrichmentRes <- enrichr(
  genes = rownames(sigRes),
  databases = c("GO_Biological_Process_2021", "KEGG_2021_Human"))
```

## Visualize enriched pathways

```{r}

#Visualize significant terms
enrichPlots <- list()

for(res in names(enrichmentRes)){
  plotDF <- enrichmentRes[[res]][1:10, ]
  plotDF$Term = str_trunc(plotDF$Term, 45)
  plotDF$Term <- factor(plotDF$Term, levels = rev(plotDF$Term))
  
  enrichPlot <- ggplot(plotDF, aes(x = Term, y = -log10(Adjusted.P.value))) +
    geom_bar(stat = "identity", width = 0.05) + geom_point(size = 3) +
    theme_minimal() +
    theme(text = element_text(size = 10),
          plot.title = element_text(hjust = (5 / nchar(res)) * 2), 
          plot.margin = margin(t = 5, r = 50, b = 5, unit = "pt"), 
          axis.text.y = element_text(size = 8)) +
    coord_flip() +
    geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "gray") + 
    theme_bw() +
    labs(title = res, y = expression("Adjusted P value, Log"[10]*""))
  enrichPlots[[res]] <- enrichPlot 
  }

{
  plot(arrangeGrob(grobs = enrichPlots))
}
```


# Variables interactions

## COVID-19 exposition, dose, sex, age, and sex.

```{r echo=FALSE}
designMatrix <- model.matrix(~ 0 + ICUstat + sex + age_bin + age_bin*sex, data = sampleTable) 
 
#Step 2: Define contrast matrix
contrastMatrix <- makeContrasts(ICUstatICU - ICUstatNonICU , levels=make.names(colnames(designMatrix)))


#Step 3: Fit model
dge <- DGEList(countTable)
dge <- calcNormFactors(dge)
dge <- estimateDisp(dge, designMatrix, robust = TRUE) 
fit <- glmQLFit(dge, designMatrix, robust = TRUE)

#Step 4: Perform hypothesis testing
res <- glmQLFTest(fit, contrast = contrastMatrix)
res <- topTags(res, n = nrow(countTable))
sigRes <- subset(res$table, FDR < 0.05 & abs(logFC) > 1) 

#Visualize results
volcanoPlot <- ggplot(res$table, aes(x = logFC, y = -log10(FDR),
                                     color = ifelse(FDR < 0.05 & abs(logFC) > 1, "darkred", "grey"))) +
  geom_point() +
  xlab(expression("Fold Change (Log"[2]*")")) +
  ylab(expression("Adjusted P value (Log"[10]*")")) +
  geom_vline(xintercept = c(-1, 1), linetype = "dotted", size = 1) + 
  geom_hline(yintercept = -log10(0.05), linetype = "dotted", size = 1) + 
  theme_minimal() +
  theme(legend.position = "none") +
  scale_colour_manual(values = c("darkred", "grey", "steelblue")) + 
  geom_text_repel(aes(x = logFC, y = -log10(FDR), 
                      label = rownames(res$table)[1:10],
                      size = 2, color = "steelblue"),
                  data = res$table[1:10, ])
print(volcanoPlot)
```

### Enrichment plot
```{r echo=FALSE}
#Visualize significant terms
enrichPlots <- list()

for(res in names(enrichmentRes)){
  plotDF <- enrichmentRes[[res]][1:10, ]
  plotDF$Term = str_trunc(plotDF$Term, 45)
  plotDF$Term <- factor(plotDF$Term, levels = rev(plotDF$Term))
  
  enrichPlot <- ggplot(plotDF, aes(x = Term, y = -log10(Adjusted.P.value))) +
    geom_bar(stat = "identity", width = 0.05) + geom_point(size = 3) +
    theme_minimal() +
    theme(text = element_text(size = 10),
          plot.title = element_text(hjust = (5 / nchar(res)) * 2), 
          plot.margin = margin(t = 5, r = 50, b = 5, unit = "pt"), 
          axis.text.y = element_text(size = 8)) +
    coord_flip() +
    geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "gray") + 
    theme_bw() +
    labs(title = res, y = expression("Adjusted P value, Log"[10]*""))
  enrichPlots[[res]] <- enrichPlot 
  }

{
  plot(arrangeGrob(grobs = enrichPlots))
}
```

# Prepare data for machine learning algorithms

```{r}
#Continuing from Day 2 slide 25
#blind = FALSE, different from before, as true because you want to eliminate the biological differnce, which is optimal for QC
# set to false if you want to do clustering or classification analysis
# already done using vst function instead of rlog.
#Filter normalized counts

## harsh filtering for perform a analysis on your computer
cofVar <- rowSds(assay(normCounts)) / rowMeans(assay(normCounts)) 
normCounts <- normCounts[cofVar > quantile(cofVar, 0.9), ] 
print(nrow(normCounts))

```

## Define caret functions

```{r}
#Define model fitting procedure
#NB: you will also need the packages statmod and e1071 for this analysis library(caret)
#New score function


rfSBF$score <- function(x, y){ 
  loadNamespace("pROC") 
  pROC::auc(pROC::roc(y, x, quiet = TRUE))[1]
}
#New filter function
rfSBF$filter <- function(score, x, y){
top100 <- order(score, decreasing = TRUE)[1:100] 
names(score) %in% names(score)[top100]
}

#Decision tree fit function
dtSBF <- rfSBF
dtSBF$fit <- function(x, y, ...){
C5.0(x = x, y = y) 
}

#using random forest
rfSBF$fit <- function(x, y,...){
randomForest::randomForest(x =x ,y=y, ntree = 3000) 
}
```

## Model fitting (C50 Decision tree)

Decision tree analysis using the ```C50``` package with Leave-one-out cross-validation (LOOCV).

```{r}

#Create training set
trainingSet <- data.frame(t(assay(normCounts)))
#Train and validate decision tree (C5.0)


#change for random forest here
dtControl <- sbfControl(functions = dtSBF, 
                         method = "loocv", 
                         saveDetails = TRUE, 
                         verbose = FALSE)

dtModel <- sbf(trainingSet, 
                sampleTable$ICUstat, 
                sbfControl = dtControl)
#Show model
summary(dtModel$fit)


{
varImp(dtModel$fit) %>%
    as.data.frame() %>%
  filter(Overall > 1) %>%
  mutate(Genes = row.names(.),
         variable=fct_reorder(Genes, Overall)) %>%
  ggplot(aes(x = Overall, y = variable)) +
    geom_point(size = 5, color = "black") +
  geom_segment( aes(y=variable, yend=variable, x=0, xend=Overall))+
  labs(x = "Overall variable importance (%)", y = "", title = "Variable importance: Decision tree model") +
    scale_x_continuous(expand = c(0,0)) +
  theme_bw()
}


```

## Model validation (C50 Decision tree)

```{r}
#function to plot confusion matrix
draw_confusion_matrix <- function(cm) {
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'Class1', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'Class2', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'Class1', cex=1.2, srt=90)
  text(140, 335, 'Class2', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  

cm <- confusionMatrix(dtModel$pred$predictions$pred, sampleTable$ICUstat)

{
 draw_confusion_matrix(cm)
}

```

## Model fitting (Random Forest)

Decision tree analysis using the ```randomForest``` package with Leave-one-out cross-validation (LOOCV).

```{r}
#Create training set
trainingSet <- data.frame(t(assay(normCounts)))
#Train and validate decision tree (C5.0)


#change for random forest here
dtControl <- sbfControl(functions = rfSBF, 
                         method = "loocv", 
                         saveDetails = TRUE, 
                         verbose = FALSE)

dtModel <- sbf(trainingSet, 
                sampleTable$ICUstat, 
                sbfControl = dtControl)
#Show model
summary(dtModel$fit)


{
randomForest::importance(dtModel$fit) %>%
    as.data.frame() %>%
  filter(MeanDecreaseGini > 1) %>%
  mutate(Genes = row.names(.),
         variable=fct_reorder(Genes, MeanDecreaseGini)) %>%
  ggplot(aes(x = MeanDecreaseGini, y = variable)) +
    geom_point(size = 5, color = "black") +
  geom_segment( aes(y=variable, yend=variable, x=0, xend=MeanDecreaseGini))+
  labs(x = "Mean Decrease Gini (variable importance)", y = "", title = "Variable importance: random forest model") +
    scale_x_continuous(expand = c(0,0)) +
  theme_bw()
}


```


## Plotting number of trees from random forest and estimated errors

```{r}
{

  plot(dtModel$fit, main = "Number of trees and error rates")

}
```

## Model validation (random forest)

```{r}
cm <- confusionMatrix(dtModel$pred$predictions$pred, sampleTable$ICUstat)

{

 draw_confusion_matrix(cm)

}
```


## Variable selection based on Machine Learning predictions

Based on the output of the decision tree and random forest, we have generated a generalized linear model based on the gene *BCL9L*. 

```{r}

# transposing normalized counts
 tCounts <- data.frame(t(assay(normCounts)))

# processing data for logistic regression
tCounts <- tCounts %>% 
  select(c(BCL9L, MYO1B, GZMH, PCOLCE2, BICDL1, PCOLCE2, FCER1A, CACNA2D2)) %>% 
  tibble::rownames_to_column() %>% 
  inner_join(sampleTable, by = c("rowname" = "sample")) %>% 
  mutate(group = if_else(ICUstat=="ICU", 1, 0))

# genelized linear model for logistic regression taking into account all gene of impotance by decision tree
#fit <- glm(group ~ BCL9L + MYO1B + GZMH + PCOLCE2 + BICDL1 + PCOLCE2 + FCER1A + CACNA2D2, data = tCounts, family = binomial) 

# genelized linear model for logistic regression taking into account the top 1 gene, BCL9L
fit <- glm(group ~ BCL9L, data = tCounts, family = binomial) 
summary(fit)

{
  plot(tCounts$BCL9L,tCounts$group,
       col=tCounts$ICUstat,
       xlab="normalised counts",
       ylab="Probability") 
# legend("topleft",levels(tCounts$group),col=1:2,pch=1) 
  a <- coef(fit)[1] # Estimated  value of a 
  b <- coef(fit)[2] # Estimated  value of b 
  x <- seq(0,15,0.1)  # x-values for the curve 
  p <- 1 / (1+exp(-(a+b*x))) 
  lines(x,p,col="blue") 

}
```






## Session info

```{r}
sessionInfo()
```