{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing supervised learning from scikit-learn\n",
    "\n",
    "Trying to predict antibody avidity based on early transcriptional signatures.\n",
    "High dimensional data, RNA-seq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spike_W6_log10</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>subject_ID</th>\n",
       "      <th>group</th>\n",
       "      <th>Spike_W6</th>\n",
       "      <th>avidity_classes</th>\n",
       "      <th>A1BG_dose1</th>\n",
       "      <th>A1BG_dose2</th>\n",
       "      <th>A2M_dose1</th>\n",
       "      <th>A2M_dose2</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSWIM5_dose2</th>\n",
       "      <th>ZSWIM7_dose1</th>\n",
       "      <th>ZSWIM7_dose2</th>\n",
       "      <th>ZSWIM8-AS1_dose1</th>\n",
       "      <th>ZSWIM8-AS1_dose2</th>\n",
       "      <th>ZXDA_dose1</th>\n",
       "      <th>ZXDA_dose2</th>\n",
       "      <th>ZYX_dose1</th>\n",
       "      <th>ZYX_dose2</th>\n",
       "      <th>prior_COVID.19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568500</td>\n",
       "      <td>222-14</td>\n",
       "      <td>222.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.702541</td>\n",
       "      <td>class1</td>\n",
       "      <td>-0.938161</td>\n",
       "      <td>-0.303003</td>\n",
       "      <td>-0.687346</td>\n",
       "      <td>-0.551431</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.698196</td>\n",
       "      <td>0.964343</td>\n",
       "      <td>-1.557709</td>\n",
       "      <td>0.395534</td>\n",
       "      <td>-2.091239</td>\n",
       "      <td>-0.740540</td>\n",
       "      <td>-1.192505</td>\n",
       "      <td>-0.703969</td>\n",
       "      <td>1.612827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601899</td>\n",
       "      <td>222-2</td>\n",
       "      <td>222.20</td>\n",
       "      <td>0</td>\n",
       "      <td>3.998521</td>\n",
       "      <td>class1</td>\n",
       "      <td>-0.669075</td>\n",
       "      <td>0.309007</td>\n",
       "      <td>-0.009108</td>\n",
       "      <td>-0.470670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262066</td>\n",
       "      <td>-0.056420</td>\n",
       "      <td>0.213994</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>-0.055847</td>\n",
       "      <td>-0.064124</td>\n",
       "      <td>-0.991309</td>\n",
       "      <td>-1.520553</td>\n",
       "      <td>-1.684161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.633819</td>\n",
       "      <td>222-7</td>\n",
       "      <td>222.70</td>\n",
       "      <td>0</td>\n",
       "      <td>4.303477</td>\n",
       "      <td>class2</td>\n",
       "      <td>-0.408948</td>\n",
       "      <td>0.054523</td>\n",
       "      <td>2.864191</td>\n",
       "      <td>-0.285388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.526551</td>\n",
       "      <td>0.058451</td>\n",
       "      <td>-0.199798</td>\n",
       "      <td>-1.895620</td>\n",
       "      <td>2.095713</td>\n",
       "      <td>-2.477863</td>\n",
       "      <td>1.692380</td>\n",
       "      <td>0.655123</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.665475</td>\n",
       "      <td>222-12</td>\n",
       "      <td>222.12</td>\n",
       "      <td>1</td>\n",
       "      <td>4.628869</td>\n",
       "      <td>class2</td>\n",
       "      <td>-1.144653</td>\n",
       "      <td>-0.743222</td>\n",
       "      <td>0.638637</td>\n",
       "      <td>-0.643280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271527</td>\n",
       "      <td>0.266331</td>\n",
       "      <td>-1.664259</td>\n",
       "      <td>-1.197889</td>\n",
       "      <td>1.582455</td>\n",
       "      <td>-0.204072</td>\n",
       "      <td>0.945781</td>\n",
       "      <td>0.146130</td>\n",
       "      <td>0.733845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.657644</td>\n",
       "      <td>222-18</td>\n",
       "      <td>222.18</td>\n",
       "      <td>1</td>\n",
       "      <td>4.546148</td>\n",
       "      <td>class2</td>\n",
       "      <td>2.614040</td>\n",
       "      <td>0.730644</td>\n",
       "      <td>-0.115901</td>\n",
       "      <td>-0.244544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086969</td>\n",
       "      <td>-0.940692</td>\n",
       "      <td>0.737124</td>\n",
       "      <td>-0.005163</td>\n",
       "      <td>0.407684</td>\n",
       "      <td>-0.132775</td>\n",
       "      <td>-0.215357</td>\n",
       "      <td>-0.406471</td>\n",
       "      <td>-0.224013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.610960</td>\n",
       "      <td>222-19</td>\n",
       "      <td>222.19</td>\n",
       "      <td>1</td>\n",
       "      <td>4.082821</td>\n",
       "      <td>class1</td>\n",
       "      <td>1.135258</td>\n",
       "      <td>0.955679</td>\n",
       "      <td>-1.195443</td>\n",
       "      <td>-1.030764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762486</td>\n",
       "      <td>2.215841</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.456305</td>\n",
       "      <td>-0.565779</td>\n",
       "      <td>0.098739</td>\n",
       "      <td>1.018252</td>\n",
       "      <td>-0.732817</td>\n",
       "      <td>-0.303002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.677384</td>\n",
       "      <td>222-15</td>\n",
       "      <td>222.15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.757559</td>\n",
       "      <td>class2</td>\n",
       "      <td>-0.857644</td>\n",
       "      <td>-1.008723</td>\n",
       "      <td>0.346561</td>\n",
       "      <td>-0.158016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573777</td>\n",
       "      <td>-0.223539</td>\n",
       "      <td>-1.015569</td>\n",
       "      <td>0.570259</td>\n",
       "      <td>-0.152506</td>\n",
       "      <td>0.840634</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>-1.371049</td>\n",
       "      <td>-0.181153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.682479</td>\n",
       "      <td>222-25</td>\n",
       "      <td>222.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4.813704</td>\n",
       "      <td>class2</td>\n",
       "      <td>0.107318</td>\n",
       "      <td>-0.281242</td>\n",
       "      <td>1.002149</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748563</td>\n",
       "      <td>1.469565</td>\n",
       "      <td>-0.817757</td>\n",
       "      <td>-0.355033</td>\n",
       "      <td>0.183282</td>\n",
       "      <td>0.028109</td>\n",
       "      <td>-0.770515</td>\n",
       "      <td>-0.044402</td>\n",
       "      <td>-0.321819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 18007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spike_W6_log10 sample_ID  subject_ID group  Spike_W6 avidity_classes  \\\n",
       "0        0.568500    222-14      222.14     0  3.702541          class1   \n",
       "1        0.601899     222-2      222.20     0  3.998521          class1   \n",
       "2        0.633819     222-7      222.70     0  4.303477          class2   \n",
       "4        0.665475    222-12      222.12     1  4.628869          class2   \n",
       "5        0.657644    222-18      222.18     1  4.546148          class2   \n",
       "6        0.610960    222-19      222.19     1  4.082821          class1   \n",
       "7        0.677384    222-15      222.15     0  4.757559          class2   \n",
       "9        0.682479    222-25      222.25     1  4.813704          class2   \n",
       "\n",
       "   A1BG_dose1  A1BG_dose2  A2M_dose1  A2M_dose2  ...  ZSWIM5_dose2  \\\n",
       "0   -0.938161   -0.303003  -0.687346  -0.551431  ...     -2.698196   \n",
       "1   -0.669075    0.309007  -0.009108  -0.470670  ...      1.262066   \n",
       "2   -0.408948    0.054523   2.864191  -0.285388  ...      1.526551   \n",
       "4   -1.144653   -0.743222   0.638637  -0.643280  ...     -0.271527   \n",
       "5    2.614040    0.730644  -0.115901  -0.244544  ...     -1.086969   \n",
       "6    1.135258    0.955679  -1.195443  -1.030764  ...      0.762486   \n",
       "7   -0.857644   -1.008723   0.346561  -0.158016  ...      1.573777   \n",
       "9    0.107318   -0.281242   1.002149   0.035139  ...     -0.748563   \n",
       "\n",
       "   ZSWIM7_dose1  ZSWIM7_dose2  ZSWIM8-AS1_dose1  ZSWIM8-AS1_dose2  ZXDA_dose1  \\\n",
       "0      0.964343     -1.557709          0.395534         -2.091239   -0.740540   \n",
       "1     -0.056420      0.213994          0.207834         -0.055847   -0.064124   \n",
       "2      0.058451     -0.199798         -1.895620          2.095713   -2.477863   \n",
       "4      0.266331     -1.664259         -1.197889          1.582455   -0.204072   \n",
       "5     -0.940692      0.737124         -0.005163          0.407684   -0.132775   \n",
       "6      2.215841      0.930144          0.456305         -0.565779    0.098739   \n",
       "7     -0.223539     -1.015569          0.570259         -0.152506    0.840634   \n",
       "9      1.469565     -0.817757         -0.355033          0.183282    0.028109   \n",
       "\n",
       "   ZXDA_dose2  ZYX_dose1  ZYX_dose2  prior_COVID.19  \n",
       "0   -1.192505  -0.703969   1.612827               0  \n",
       "1   -0.991309  -1.520553  -1.684161               0  \n",
       "2    1.692380   0.655123   0.855714               0  \n",
       "4    0.945781   0.146130   0.733845               1  \n",
       "5   -0.215357  -0.406471  -0.224013               1  \n",
       "6    1.018252  -0.732817  -0.303002               1  \n",
       "7    0.152697  -1.371049  -0.181153               0  \n",
       "9   -0.770515  -0.044402  -0.321819               1  \n",
       "\n",
       "[8 rows x 18007 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Read in the data to a pandas DataFrame using the read_csv method.\n",
    "test_index = [3,8]\n",
    "\n",
    "train=pd.read_csv('../data/machine_learning_dataset/fold_changes_RPKMs.csv')\n",
    "train.loc[train.group == \"Neg\", 'group'] = 0\n",
    "train.loc[train.group == \"Pos\", 'group'] = 1\n",
    "train['Spike_W6_log10'] = np.log10(train['Spike_W6'])\n",
    "spike_col=train['Spike_W6_log10']\n",
    "train.drop(labels=['Spike_W6_log10'], axis=1,inplace = True)\n",
    "train.insert(0, 'Spike_W6_log10', spike_col)\n",
    "    \n",
    "#test=train.iloc[test_index]\n",
    "train=train.drop(train.index[test_index])\n",
    "\n",
    "\n",
    "# We are using the train data as placeholder for the test data,\n",
    "# so we can implement code to run predictions on the test pandas DataFrame as well.\n",
    "test=train.copy() \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation sets\n",
    "\n",
    "LOOCV will be used\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Data was already scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data for training.\n",
    "Set up the data by making a numpy matrix of the training data called `X`, numpy vector with the target values `Y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "\n",
    "(size_x,size_y)=train.shape\n",
    "target_index=size_y-2\n",
    "\n",
    "\n",
    "\n",
    "#Put the training data in X the .values method returns a numpy matrix of the numbers in the DataFrame.\n",
    "X=train.iloc[:,6:].values #,0:target_index]\n",
    "\n",
    "#Create the same for the test (currently this is the same as train just to keep to code running)\n",
    "X_test=test.iloc[:,6:].values\n",
    "#print X\n",
    "\n",
    "#Put the target value in Y\n",
    "Y=train['Spike_W6_log10'].values\n",
    "Y_test=test['Spike_W6_log10'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Machine Learning Methods\n",
    "Finally we can train machine learning methods... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: -0.040055 (0.018107)\n",
      "LRR: -0.040265 (0.017757)\n",
      "LLR: -0.038258 (0.020537)\n",
      "DTR: -0.052227 (0.017615)\n",
      "KNN: -0.041592 (0.017314)\n",
      "CART: -0.045472 (0.025880)\n",
      "RF: -0.039596 (0.019802)\n",
      "KERNEL: -1.141692 (0.106388)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# Prepare models\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LRR', Ridge()))\n",
    "models.append(('LLR', Lasso()))\n",
    "models.append(('DTR', DecisionTreeRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('RF', RandomForestRegressor()))\n",
    "models.append(('KERNEL', KernelRidge()))\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=len(X), random_state=seed, shuffle=True)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# Boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot([abs(ele) for ele in results],patch_artist=True)\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig('../results/2022-06-12/ML_methods_test.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
